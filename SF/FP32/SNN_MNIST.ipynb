{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "622dd8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, torch, torch.nn as nn, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de36e18",
   "metadata": {},
   "source": [
    "**parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3cfc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in, num_hid, num_out = 784, 256, 10\n",
    "beta, T, bs, epochs, lr = 1, 50, 128, 3, 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38397089",
   "metadata": {},
   "source": [
    "**device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554678c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2821d27fc90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874dbaa8",
   "metadata": {},
   "source": [
    "**arch network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5bc651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2d2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1  = nn.Linear(num_in , num_hid, bias=False)\n",
    "        self.lif1 = snn.Leaky(beta=beta,threshold=0.8,reset_mechanism=\"zero\")\n",
    "        self.fc2  = nn.Linear(num_hid, num_out, bias=False)\n",
    "        self.lif2 = snn.Leaky(beta=beta,threshold=0.8,reset_mechanism=\"zero\")\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.fc1.weight.dtype)\n",
    "        mem1 = self.lif1.init_leaky().to(device=x.device, dtype=x.dtype)\n",
    "        mem2 = self.lif2.init_leaky().to(device=x.device, dtype=x.dtype)\n",
    "        out  = []\n",
    "        for t in range(x.size(0)):\n",
    "            spk1, mem1 = self.lif1(self.fc1(x[t]), mem1)\n",
    "            spk1 = spk1.to(dtype=self.fc2.weight.dtype)        #\n",
    "            spk2, mem2 = self.lif2(self.fc2(spk1), mem2)\n",
    "            out.append(spk2)\n",
    "        return torch.stack(out)                                # [T,B,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd6624d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = torchvision.datasets.MNIST(\"data\", True , download=True, transform=tr)\n",
    "test_ds  = torchvision.datasets.MNIST(\"data\", False, download=True, transform=tr)\n",
    "train_ld = DataLoader(train_ds, bs, True , num_workers=2, pin_memory=True)\n",
    "test_ld  = DataLoader(test_ds , bs, False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8cf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SNN().to(device)\n",
    "opt = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa76cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01de613b",
   "metadata": {},
   "source": [
    "**train phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0468a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_ld,epochs):\n",
    "    for ep in range(1, epochs + 1):\n",
    "        net.train()\n",
    "        for imgs, lbls in tqdm(train_ld, desc=f\"train {ep}/{epochs}\"):\n",
    "            imgs = imgs.to(device).view(imgs.size(0), -1) \n",
    "            lbls = lbls.to(device)\n",
    "            spk  = spikegen.rate(imgs, T).to(device)\n",
    "            loss = loss_fn(net(spk).sum(0), lbls)\n",
    "            opt.zero_grad(); loss.backward(); opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0376ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 1/3: 100%|██████████| 469/469 [03:47<00:00,  2.06it/s]\n",
      "train 2/3: 100%|██████████| 469/469 [03:30<00:00,  2.23it/s]\n",
      "train 3/3: 100%|██████████| 469/469 [01:54<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# train(net,train_ld,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae666a1",
   "metadata": {},
   "source": [
    "**test phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f888115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,loader):\n",
    "    @torch.no_grad()\n",
    "    def evaluate(model, loader, dtype):\n",
    "        model.eval()\n",
    "        correct = total = 0\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = (imgs.to(device).view(imgs.size(0), -1) ).to(dtype)\n",
    "            spk  = spikegen.rate(imgs, T).to(dtype).to(device)\n",
    "            preds = model(spk).sum(0).argmax(1)\n",
    "            correct += (preds == lbls.to(device)).sum().item()\n",
    "            total   += lbls.size(0)\n",
    "        return 100 * correct / total\n",
    "\n",
    "\n",
    "    acc32 = evaluate(net, test_ld, torch.float32)\n",
    "\n",
    "\n",
    "    net_fp16 = SNN().to(device)\n",
    "    net_fp16.load_state_dict(net.state_dict())\n",
    "    net_fp16.half().eval()\n",
    "    acc16 = evaluate(net_fp16, test_ld, torch.float16)\n",
    "\n",
    "    print(f\"Accuracy FP32 : {acc32:.2f}%\")\n",
    "    print(f\"Accuracy FP16 : {acc16:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da97f596",
   "metadata": {},
   "source": [
    "create a test data spike train for cpp program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n",
      "Spike array shape: torch.Size([50, 784])\n",
      "Spike array (as int):\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# imgs, lbls = next(iter(test_ld))\n",
    "\n",
    "# img = imgs[1].to(device)\n",
    "# label = lbls[1].item()\n",
    "\n",
    "# img_flat = img.view(-1)\n",
    "\n",
    "\n",
    "# spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1) \n",
    "\n",
    "# print(\"Label:\", label)\n",
    "# print(\"Spike array shape:\", spk.shape)  # [T, 784]\n",
    "# print(\"Spike array (as int):\")\n",
    "# print(spk.int())\n",
    "\n",
    "# spk_t = spk.int().cpu().tolist()  \n",
    "\n",
    "# with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\spikes.cpp\", \"w\") as f:\n",
    "#     f.write(\"#include <vector>\\n\")\n",
    "#     f.write(\"#include \\\"spikes.h\\\"\\n\")\n",
    "#     f.write(f\"int label = {label};\\n\")\n",
    "#     f.write(\"std::vector<std::vector<int>> spike_input = {\\n\")\n",
    "    \n",
    "#     for i, row in enumerate(spk_t): \n",
    "#         row_str = \", \".join(str(x) for x in row)\n",
    "#         comma = \",\" if i < len(spk_t) - 1 else \"\"\n",
    "#         f.write(f\"    {{{row_str}}}{comma}\\n\")\n",
    "#     f.write(\"};\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bcb16",
   "metadata": {},
   "source": [
    "create dataset for test with cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416e0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 1000  \n",
    "\n",
    "# all_spikes = []\n",
    "# all_labels = []\n",
    "\n",
    "# for batch_imgs, batch_lbls in test_ld:\n",
    "#     for i in range(len(batch_imgs)):\n",
    "#         if len(all_labels) >= num_samples:\n",
    "#             break\n",
    "\n",
    "#         img = batch_imgs[i].to(device)\n",
    "#         label = batch_lbls[i].item()\n",
    "#         img_flat = img.view(-1)\n",
    "\n",
    "#         spk = spikegen.rate(img_flat.unsqueeze(0), T).squeeze(1)  \n",
    "#         spk_np = spk.int().cpu().tolist()  \n",
    "\n",
    "#         all_spikes.append(spk_np)         \n",
    "#         all_labels.append(label)          \n",
    "\n",
    "#     if len(all_labels) >= num_samples:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6c55fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#     # with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\QNN\\\\HW\\\\FP32\\\\TestDataset.cpp\", \"w\") as f:\n",
    "# #     f.write(\"#include <vector>\\n\")\n",
    "# #     f.write(\"#include \\\"TestDataset.h\\\"\\n\")\n",
    "# #     f.write(\"std::vector<int> labels = {\\n\")\n",
    "# #     f.write(\"    \" + \", \".join(str(lbl) for lbl in all_labels) + \"\\n};\\n\\n\")\n",
    "\n",
    "# #     f.write(\"std::vector<std::vector<std::vector<int>>> dataset_spikes = {\\n\")\n",
    "# #     for i, sample in enumerate(all_spikes):\n",
    "# #         f.write(\"    {\\n\")\n",
    "# #         for j, timestep in enumerate(sample):\n",
    "# #             row_str = \", \".join(str(x) for x in timestep)\n",
    "# #             comma = \",\" if j < len(sample) - 1 else \"\"\n",
    "# #             f.write(f\"        {{{row_str}}}{comma}\\n\")\n",
    "# #         comma_sample = \",\" if i < len(all_spikes) - 1 else \"\"\n",
    "# #         f.write(f\"    }}{comma_sample}\\n\")\n",
    "# #     f.write(\"};\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362fbda",
   "metadata": {},
   "source": [
    "datatest with txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbbaafec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "T = 50\n",
    "num_samples = 10000\n",
    "\n",
    "label_file = open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\posit\\\\labels.txt\", \"w\")\n",
    "spike_file = open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\posit\\\\spikes.txt\", \"w\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    count = 0\n",
    "    for batch_imgs, batch_lbls in test_ld:\n",
    "        for i in range(len(batch_imgs)):\n",
    "            if count >= num_samples:\n",
    "                break\n",
    "\n",
    "            img = batch_imgs[i].to(device)\n",
    "            label = batch_lbls[i].item()\n",
    "\n",
    "            img_flat = img.view(-1).unsqueeze(0)                 # [1, 784]\n",
    "            spk = spikegen.rate(img_flat, T)                     # [T, 1, 784]\n",
    "            spk = spk.squeeze(1).int().cpu()                     # [T, 784]\n",
    "\n",
    "            if spk.shape != (T, 784):\n",
    "                raise ValueError(f\"Expected shape [50, 784], got {spk.shape}\")\n",
    "\n",
    "            spike_file.write(f\"# sample {count}\\n\")\n",
    "            for timestep in spk:\n",
    "                line = \" \".join(str(bit.item()) for bit in timestep)\n",
    "                spike_file.write(line + \"\\n\")\n",
    "\n",
    "            label_file.write(f\"{label}\\n\")\n",
    "            count += 1\n",
    "\n",
    "        if count >= num_samples:\n",
    "            break\n",
    "\n",
    "spike_file.close()\n",
    "label_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b540b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model_weights.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "873a3511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy FP32 : 95.25%\n",
      "Accuracy FP16 : 95.22%\n"
     ]
    }
   ],
   "source": [
    "test(net,test_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d755096",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dca06a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_fp16 = SNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee71c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_fp16.load_state_dict(net.state_dict())\n",
    "net_fp16 = net_fp16.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "037ea01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.000267386436462402343750000000,  0.019158702343702316284179687500,\n",
       "         -0.029394470155239105224609375000,  ...,\n",
       "          0.021935582160949707031250000000,  0.003732603043317794799804687500,\n",
       "          0.002060331404209136962890625000],\n",
       "        [-0.019777085632085800170898437500, -0.014981266111135482788085937500,\n",
       "         -0.010442411527037620544433593750,  ...,\n",
       "         -0.020264618098735809326171875000, -0.005962418392300605773925781250,\n",
       "         -0.029945783317089080810546875000],\n",
       "        [-0.020148508250713348388671875000,  0.014898568391799926757812500000,\n",
       "         -0.033275961875915527343750000000,  ...,\n",
       "         -0.020343888550996780395507812500,  0.001181673258543014526367187500,\n",
       "          0.008027642965316772460937500000],\n",
       "        ...,\n",
       "        [-0.003743059933185577392578125000, -0.022719830274581909179687500000,\n",
       "          0.033580925315618515014648437500,  ...,\n",
       "         -0.023739803582429885864257812500,  0.020168386399745941162109375000,\n",
       "         -0.034363791346549987792968750000],\n",
       "        [-0.026030030101537704467773437500, -0.019972151145339012145996093750,\n",
       "         -0.019778678193688392639160156250,  ...,\n",
       "         -0.030644839629530906677246093750,  0.009507227689027786254882812500,\n",
       "          0.031681973487138748168945312500],\n",
       "        [-0.021993532776832580566406250000,  0.018262993544340133666992187500,\n",
       "          0.006696656346321105957031250000,  ...,\n",
       "          0.009256668388843536376953125000, -0.025757739320397377014160156250,\n",
       "         -0.014133816584944725036621093750]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1563e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.000267505645751953125000000000,  0.019165039062500000000000000000,\n",
       "         -0.029388427734375000000000000000,  ...,\n",
       "          0.021942138671875000000000000000,  0.003732681274414062500000000000,\n",
       "          0.002059936523437500000000000000],\n",
       "        [-0.019775390625000000000000000000, -0.014984130859375000000000000000,\n",
       "         -0.010444641113281250000000000000,  ...,\n",
       "         -0.020263671875000000000000000000, -0.005962371826171875000000000000,\n",
       "         -0.029953002929687500000000000000],\n",
       "        [-0.020141601562500000000000000000,  0.014900207519531250000000000000,\n",
       "         -0.033264160156250000000000000000,  ...,\n",
       "         -0.020339965820312500000000000000,  0.001181602478027343750000000000,\n",
       "          0.008026123046875000000000000000],\n",
       "        ...,\n",
       "        [-0.003742218017578125000000000000, -0.022720336914062500000000000000,\n",
       "          0.033569335937500000000000000000,  ...,\n",
       "         -0.023742675781250000000000000000,  0.020172119140625000000000000000,\n",
       "         -0.034362792968750000000000000000],\n",
       "        [-0.026031494140625000000000000000, -0.019973754882812500000000000000,\n",
       "         -0.019775390625000000000000000000,  ...,\n",
       "         -0.030639648437500000000000000000,  0.009506225585937500000000000000,\n",
       "          0.031677246093750000000000000000],\n",
       "        [-0.021987915039062500000000000000,  0.018264770507812500000000000000,\n",
       "          0.006694793701171875000000000000,  ...,\n",
       "          0.009254455566406250000000000000, -0.025756835937500000000000000000,\n",
       "         -0.014137268066406250000000000000]], dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_fp16.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(),'model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444277c7",
   "metadata": {},
   "source": [
    "Write weights with format cpp in weights.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b0880f",
   "metadata": {},
   "source": [
    "with 6 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0361a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.eval()\n",
    "# with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\HW\\\\FP32\\\\weightst.cpp\", \"w\") as cpp_file:\n",
    "#     cpp_file.write(\"#include <vector>\\n\\n\")\n",
    "#     cpp_file.write(\"#include \\\"weights.h\\\"\\n\\n\")\n",
    "\n",
    "#     for name, param in net.state_dict().items():\n",
    "#         cpp_name = name.replace(\".\", \"_\")\n",
    "#         data = param.cpu().numpy()\n",
    "#         shape = data.shape\n",
    "\n",
    "#         if \"weight\" in name and len(shape) == 2:\n",
    "#             data = data.T  # Transpose to [input][output]\n",
    "#             shape = data.shape\n",
    "\n",
    "#             cpp_file.write(f\"// shape: {shape} // Transposed\\n\")\n",
    "#             cpp_file.write(f\"std::vector<std::vector<float>> {cpp_name} = {{\\n\")\n",
    "\n",
    "#             for row in data:\n",
    "#                 row_str = \", \".join(f\"{v:.6f}\" for v in row)\n",
    "#                 cpp_file.write(f\"    {{{row_str}}},\\n\")\n",
    "\n",
    "#             cpp_file.write(\"};\\n\\n\")\n",
    "\n",
    "#         elif \"bias\" in name and len(shape) == 1:\n",
    "#             cpp_file.write(f\"// shape: {shape}\\n\")\n",
    "#             cpp_file.write(f\"std::vector<float> {cpp_name} = {{\\n    \")\n",
    "#             cpp_file.write(\", \".join(f\"{v:.6f}\" for v in data))\n",
    "#             cpp_file.write(\"\\n};\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0261ac8",
   "metadata": {},
   "source": [
    "with 25 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c47744be",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with open(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\shayan\\\\QNN\\\\posit\\\\weights.cpp\", \"w\") as cpp_file:\n",
    "    cpp_file.write(\"#include <vector>\\n\\n\")\n",
    "    cpp_file.write(\"#include \\\"weights.h\\\"\\n\\n\")\n",
    "\n",
    "    for name, param in net.state_dict().items():\n",
    "        cpp_name = name.replace(\".\", \"_\")\n",
    "        data = param.cpu().numpy()\n",
    "        shape = data.shape\n",
    "\n",
    "        if \"weight\" in name and len(shape) == 2:\n",
    "            data = data.T  # Transpose to [input][output]\n",
    "            shape = data.shape\n",
    "\n",
    "            cpp_file.write(f\"// shape: {shape} // Transposed\\n\")\n",
    "            cpp_file.write(f\"const std::vector<std::vector<float>> {cpp_name} = {{\\n\")\n",
    "\n",
    "            for row in data:\n",
    "                row_str = \", \".join(f\"{v:.25f}\" for v in row)  \n",
    "                cpp_file.write(f\"    {{{row_str}}},\\n\")\n",
    "\n",
    "            cpp_file.write(\"};\\n\\n\")\n",
    "\n",
    "        elif \"bias\" in name and len(shape) == 1:\n",
    "            cpp_file.write(f\"// shape: {shape}\\n\")\n",
    "            cpp_file.write(f\"const std::vector<float> {cpp_name} = {{\\n    \")\n",
    "            cpp_file.write(\", \".join(f\"{v:.25f}\" for v in data)) \n",
    "            cpp_file.write(\"\\n};\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78264a",
   "metadata": {},
   "source": [
    "***julia format for weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fdaa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_weights_to_julia(state_dict, filename=\"weights.jl\"):\n",
    "\n",
    "    with open(filename, \"w\") as jl_file:\n",
    "        jl_file.write(\"# This file contains model weights exported from PyTorch to Julia format.\\n\\n\")\n",
    "\n",
    "        for name, param in state_dict.items():\n",
    "            julia_name = name.replace(\".\", \"_\")\n",
    "            data = param.cpu().numpy()\n",
    "            shape = data.shape\n",
    "\n",
    "            if \"weight\" in name and len(shape) == 2:\n",
    "                # Transpose the weight matrix for compatibility.\n",
    "                data = data.T\n",
    "                shape = data.shape\n",
    "\n",
    "                jl_file.write(f\"# shape: {shape} # Transposed\\n\")\n",
    "                jl_file.write(f\"const {julia_name} = [\\n\")\n",
    "\n",
    "                for i, row in enumerate(data):\n",
    "                    row_str = \", \".join(f\"{v:.25f}\" for v in row)\n",
    "                    separator = \";\\n\" if i < len(data) - 1 else \"\\n\"\n",
    "                    jl_file.write(f\"    {row_str}{separator}\")\n",
    "\n",
    "                jl_file.write(\"]\\n\\n\")\n",
    "net.eval()\n",
    "\n",
    "save_weights_to_julia(net.state_dict())\n",
    "\n",
    "print(\"Weights have been saved to weights.jl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d987950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
